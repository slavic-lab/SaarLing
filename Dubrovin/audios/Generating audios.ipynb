{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe8cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"THE_PATH_TO_YOUR_CONFIG_JSON_FROM_GOOGLE\"\n",
    "print(os.path.exists(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271de916",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-texttospeech python-slugify pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ea605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "from google.cloud import texttospeech\n",
    "from google.api_core.exceptions import InvalidArgument\n",
    "\n",
    "CSV_PATH   = \"EN.csv\"  # the path to csv you want to voice\n",
    "COLUMN     = \"head_ru\"  # specify the column name\n",
    "OUT_DIR    = \"tts_ru_zephyr_long_only\" # output directory\n",
    "PACE       = 0.95\n",
    "PITCH      = 0.0\n",
    "USE_EU_EP  = False\n",
    "START      = 0\n",
    "LIMIT      = None\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "if USE_EU_EP:\n",
    "    from google.api_core.client_options import ClientOptions\n",
    "    client = texttospeech.TextToSpeechClient(\n",
    "        client_options=ClientOptions(api_endpoint=\"eu-texttospeech.googleapis.com\")\n",
    "    )\n",
    "else:\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "LANG_CODE      = \"ru-RU\" # en-GB, de-DE \n",
    "VOICE_PRIMARY  = \"ru-RU-Chirp3-HD-Zephyr\" \n",
    "VOICE_FALLBACK = \"ru-RU-Chirp-HD-Zephyr\"\n",
    "\n",
    "voices = client.list_voices().voices\n",
    "def has_voice(name: str) -> bool:\n",
    "    return any(v.name == name for v in voices)\n",
    "\n",
    "if not has_voice(VOICE_PRIMARY):\n",
    "    print(f\"Warning: {VOICE_PRIMARY} not found in list_voices(). Will still try it.\")\n",
    "if not has_voice(VOICE_FALLBACK):\n",
    "    print(f\"Warning: {VOICE_FALLBACK} not found in list_voices(). Fallback may fail.\")\n",
    "\n",
    "\n",
    "def expand_slashes_en(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.strip()\n",
    "    # word1 / word2 -> word1 or word2\n",
    "    text = re.sub(r\"\\b(\\w+)\\s*/\\s*(\\w+)\\b\", r\"\\1 Ð¸Ð»Ð¸ \\2\", text) # replace Ð¸Ð»Ð¸ with or/oder (depends on a language obviously)\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_idiom(raw: str) -> str:\n",
    "    if not isinstance(raw, str):\n",
    "        raw = str(raw)\n",
    "    s = raw.strip()\n",
    "    s = s.replace(\"â€”\", \"-\").replace(\"â€“\", \"-\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "def build_long_context_en(idiom_tts: str) -> str:\n",
    "    # Change the language of the text if needed\n",
    "    return (\n",
    "    f\"Ð’ ÑÑ‚Ð¾Ð¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ðµ Ð²Ñ‹ ÑƒÑÐ»Ñ‹ÑˆÐ¸Ñ‚Ðµ Ñ€ÑƒÑÑÐºÑƒÑŽ Ð¸Ð´Ð¸Ð¾Ð¼Ñƒ: Â«{idiom_tts}Â». \"\n",
    "    f\"Ð­Ñ‚Ð° Ð¸Ð´Ð¸Ð¾Ð¼Ð° Ñ‡Ð°ÑÑ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² Ð¿Ð¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ð¾Ð¹ Ñ€ÐµÑ‡Ð¸ Ð¸ Ð¸Ð¼ÐµÐµÑ‚ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ½Ð¾Ðµ Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ð·Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ. \"\n",
    "    f\"Ð¯ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽ ÐµÑ‘ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð±Ñ‹Ð»Ð¾ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾ ÑÐ»Ñ‹ÑˆÐ½Ð¾: {idiom_tts}. \"\n",
    "    f\"Ð˜ Ð½Ð°Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ðº Ð²Ñ‹ ÑƒÑÐ»Ñ‹ÑˆÐ¸Ñ‚Ðµ ÑÑ‚Ñƒ Ð¸Ð´Ð¸Ð¾Ð¼Ñƒ Ð² Ñ‚Ñ€ÐµÑ‚Ð¸Ð¹ Ñ€Ð°Ð·, Ð² ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ð¾Ð¼ Ð¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¼ Ñ‚ÐµÐ¼Ð¿Ðµ Ñ€ÐµÑ‡Ð¸: {idiom_tts}.\"\n",
    "    )\n",
    "\n",
    "def synthesize_en(text: str, voice_name: str):\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=LANG_CODE,\n",
    "        name=voice_name,\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "        speaking_rate=PACE,\n",
    "        pitch=PITCH,\n",
    "    )\n",
    "    return client.synthesize_speech(\n",
    "        input=synthesis_input,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config,\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, sep=\";\")\n",
    "if COLUMN not in df.columns:\n",
    "    raise ValueError(f\"Column '{COLUMN}' not found. Available: {list(df.columns)}\")\n",
    "\n",
    "series = df[COLUMN]\n",
    "\n",
    "\n",
    "if LIMIT is not None:\n",
    "    series = series.iloc[START:START+LIMIT]\n",
    "else:\n",
    "    series = series.iloc[START:]\n",
    "\n",
    "\n",
    "if \"id\" in df.columns:\n",
    "    ids = df.loc[series.index, \"id\"].astype(int).tolist()\n",
    "else:\n",
    "    ids = list(range(1 + START, 1 + START + len(series)))\n",
    "\n",
    "ok, fail = 0, 0\n",
    "\n",
    "for (row_idx, idiom_raw), num in zip(series.items(), ids):\n",
    "    # skip NaNs\n",
    "    if pd.isna(idiom_raw):\n",
    "        print(f\"skip (NaN) id={num}\")\n",
    "        continue\n",
    "\n",
    "    raw = str(idiom_raw).strip()\n",
    "    if not raw:\n",
    "        print(f\"skip (empty) id={num}\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    idiom_norm = clean_idiom(raw)\n",
    "\n",
    "    idiom_tts = expand_slashes_en(idiom_norm)\n",
    "    text      = build_long_context_en(idiom_tts)\n",
    "\n",
    "    base = f\"{int(num):04d}_{slugify(idiom_norm)[:60]}\"\n",
    "    out_path = os.path.join(OUT_DIR, f\"{base}.mp3\")\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        print(\"skip (exists)\", out_path)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        resp = synthesize_en(text, VOICE_PRIMARY)\n",
    "    except InvalidArgument as e:\n",
    "        msg = str(e).lower()\n",
    "        if \"requires a model\" in msg or \"invalid voice\" in msg:\n",
    "            try:\n",
    "                resp = synthesize_en(text, VOICE_FALLBACK)\n",
    "            except Exception as e2:\n",
    "                print(f\"{num}: {raw} â†’ Chirp fallback failed:\", e2)\n",
    "                fail += 1\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"{num}: {raw} â†’\", e)\n",
    "            fail += 1\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"{num}: {raw} â†’\", e)\n",
    "        fail += 1\n",
    "        continue\n",
    "\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(resp.audio_content)\n",
    "    print(\"Done!\", out_path)\n",
    "    ok += 1\n",
    "\n",
    "print(f\"\\nDone. Saved: {ok}, Failed: {fail}\")\n",
    "print(\"Output folder:\", os.path.abspath(OUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0106d",
   "metadata": {},
   "source": [
    "## Extracting actual idioms with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b316c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "from pydub import silence\n",
    "from pydub.silence import detect_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_silence\n",
    "import whisper\n",
    "\n",
    "CSV_PATH    = \"/content/drive/My Drive/Dubrovin/CSVS/Final/EN.csv\" # your  CSV\n",
    "COLUMN      = \"head_ru\"                                            # idiom column\n",
    "AUDIO_DIR   = \"/content/drive/My Drive/Dubrovin/tts_ru_zephyr_long_only\" # long context audios\n",
    "OUTPUT_DIR  = \"/content/drive/My Drive/Dubrovin/tts_ru_SHORT_FIXED\"  # where to save idiom-only\n",
    "LANG_CODE   = \"ru\"\n",
    "MODEL_NAME  = \"small\"\n",
    "MIN_MATCH_RATIO = 0.6  # how strict matching idiom words vs ASR\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ”Š Loading Whisper model:\", MODEL_NAME)\n",
    "model = whisper.load_model(MODEL_NAME)\n",
    "\n",
    "\n",
    "def normalize_token(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"[^\\wÃ¤Ã¶Ã¼ÃŸ]+\", \"\", s, flags=re.UNICODE)  # keep letters/digits/umlauts\n",
    "    return s\n",
    "\n",
    "def tokenize_idiom(idiom: str):\n",
    "    return [normalize_token(t) for t in re.split(r\"\\s+\", idiom) if normalize_token(t)]\n",
    "\n",
    "def flatten_whisper_words(result):\n",
    "    words = []\n",
    "    for seg in result.get(\"segments\", []):\n",
    "        for w in seg.get(\"words\", []):\n",
    "            text = w.get(\"word\", \"\")  # often with leading space\n",
    "            words.append({\n",
    "                \"text\": text,\n",
    "                \"norm\": normalize_token(text),\n",
    "                \"start\": float(w.get(\"start\", 0.0)),\n",
    "                \"end\": float(w.get(\"end\", 0.0)),\n",
    "            })\n",
    "    return words\n",
    "\n",
    "import math\n",
    "\n",
    "def find_loose_idiom_span(words, idiom_tokens, min_fraction=0.5):\n",
    "    \"\"\"\n",
    "    Fallback: instead of requiring a contiguous window,\n",
    "    we find all words whose norm is in idiom_tokens and\n",
    "    take min(start), max(end) over them.\n",
    "\n",
    "    min_fraction = fraction of idiom tokens that must be present\n",
    "    to accept the span (e.g. 0.5 = at least half the words).\n",
    "    \"\"\"\n",
    "    if not words or not idiom_tokens:\n",
    "        return None, None\n",
    "\n",
    "    # map token -> list of (start, end) times\n",
    "    matches = []\n",
    "    for w in words:\n",
    "        if w[\"norm\"] in idiom_tokens:\n",
    "            matches.append((w[\"start\"], w[\"end\"]))\n",
    "\n",
    "    if not matches:\n",
    "        return None, None\n",
    "\n",
    "    needed = max(1, math.ceil(len(idiom_tokens) * min_fraction))\n",
    "    # how many distinct idiom tokens we saw at least once\n",
    "    seen_tokens = set()\n",
    "    for w in words:\n",
    "        if w[\"norm\"] in idiom_tokens:\n",
    "            seen_tokens.add(w[\"norm\"])\n",
    "\n",
    "    if len(seen_tokens) < needed:\n",
    "        return None, None\n",
    "\n",
    "    # span from first to last matched word\n",
    "    starts = [s for (s, e) in matches]\n",
    "    ends   = [e for (s, e) in matches]\n",
    "    return min(starts), max(ends)\n",
    "\n",
    "\n",
    "def find_best_idiom_span(words, idiom_tokens, min_ratio=0.6):\n",
    "    if not words or not idiom_tokens:\n",
    "        return None, None\n",
    "\n",
    "    n = len(words)\n",
    "    m = len(idiom_tokens)\n",
    "    best_score = 0.0\n",
    "    best_span = (None, None)\n",
    "\n",
    "    for i in range(0, max(0, n - m + 1)):\n",
    "        window = words[i:i+m]\n",
    "        matches = 0\n",
    "        for j, tok in enumerate(idiom_tokens):\n",
    "            if not tok:\n",
    "                continue\n",
    "            if window[j][\"norm\"] == tok:\n",
    "                matches += 1\n",
    "        ratio = matches / m\n",
    "        if ratio > best_score:\n",
    "            best_score = ratio\n",
    "            start_sec = window[0][\"start\"]\n",
    "            end_sec   = window[-1][\"end\"]\n",
    "            best_span = (start_sec, end_sec)\n",
    "\n",
    "    if best_score >= min_ratio and best_span[0] is not None and best_span[1] > best_span[0]:\n",
    "        return best_span\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def strip_silence_segment(segment, silence_db_offset=30, padding_ms=80):\n",
    "    if len(segment) == 0:\n",
    "        return segment\n",
    "\n",
    "    silence_thresh = segment.dBFS - silence_db_offset\n",
    "\n",
    "    silences = detect_silence(\n",
    "        segment,\n",
    "        min_silence_len=150,    # ms\n",
    "        silence_thresh=silence_thresh\n",
    "    )\n",
    "\n",
    "    if not silences:\n",
    "        return segment  # nothing detected\n",
    "\n",
    "    leading_trim = 0\n",
    "    trailing_trim = len(segment)\n",
    "\n",
    "    for start, end in silences:\n",
    "        if start == 0:\n",
    "            # silence at start\n",
    "            leading_trim = max(leading_trim, end)\n",
    "        if end == len(segment):\n",
    "            # silence at end\n",
    "            trailing_trim = min(trailing_trim, start)\n",
    "\n",
    "    if trailing_trim <= leading_trim:\n",
    "        return segment\n",
    "\n",
    "    start_ms = max(0, leading_trim - padding_ms)\n",
    "    end_ms   = min(len(segment), trailing_trim + padding_ms)\n",
    "    return segment[start_ms:end_ms]\n",
    "\n",
    "def cut_audio_segment(input_path, start_sec, end_sec, output_path):\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    start_ms = int(start_sec * 1000)\n",
    "    end_ms   = int(end_sec * 1000)\n",
    "\n",
    "    start_ms = max(0, min(start_ms, len(audio)))\n",
    "    end_ms   = max(0, min(end_ms, len(audio)))\n",
    "    if end_ms <= start_ms:\n",
    "        raise ValueError(\"end_ms <= start_ms after clamping\")\n",
    "\n",
    "    segment = audio[start_ms:end_ms]\n",
    "\n",
    "    # trim silence at edges\n",
    "    segment = strip_silence_segment(\n",
    "        segment,\n",
    "        silence_db_offset=30,\n",
    "        padding_ms=80          # leave 80ms at both ends\n",
    "    )\n",
    "\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    segment.export(output_path, format=\"mp3\")\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(AUDIO_DIR) if f.lower().endswith(\".mp3\")]\n",
    "prefix_map = {}\n",
    "for f in files:\n",
    "    prefix = f.split(\"_\", 1)[0]\n",
    "    prefix_map.setdefault(prefix, []).append(f)\n",
    "\n",
    "print(f\" Found {len(files)} long audio files in {AUDIO_DIR}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, sep=\";\")\n",
    "if COLUMN not in df.columns:\n",
    "    raise ValueError(f\"Column '{COLUMN}' not in CSV. Available: {list(df.columns)}\")\n",
    "\n",
    "if \"id\" in df.columns:\n",
    "    ids = df[\"id\"].astype(int).tolist()\n",
    "else:\n",
    "    ids = list(range(1, len(df) + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok, fail, skipped = 0, 0, 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    num = ids[idx]\n",
    "    raw = row[COLUMN]\n",
    "\n",
    "    if pd.isna(raw) or str(raw).strip() == \"\":\n",
    "        print(f\" skip (empty/Nan) id={num}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    idiom_raw = str(raw).strip()\n",
    "    idiom_tokens = tokenize_idiom(idiom_raw)\n",
    "    if not idiom_tokens:\n",
    "        print(f\" skip (no tokens) id={num} text={idiom_raw!r}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    prefix = f\"{int(num):04d}\"\n",
    "    candidates = prefix_map.get(prefix, [])\n",
    "    if not candidates:\n",
    "        print(f\"! id={num} ({idiom_raw!r}) â†’ no audio file starting with {prefix}_* in {AUDIO_DIR}\")\n",
    "        fail += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    audio_file = candidates[0]\n",
    "    audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
    "\n",
    "    base_slug = slugify(idiom_raw.lower())[:60]\n",
    "    out_file  = f\"{prefix}_{base_slug}_idiom.mp3\"\n",
    "    out_path  = os.path.join(OUTPUT_DIR, out_file)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\" skip (exists) {out_path}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n id={num} | file={audio_file} | idiom={idiom_raw}\")\n",
    "\n",
    "    # Transcribe with word timestamps\n",
    "    try:\n",
    "        result = model.transcribe(\n",
    "            audio_path,\n",
    "            language=LANG_CODE,\n",
    "            word_timestamps=True,\n",
    "            verbose=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\" id={num} â†’ Whisper error:\", e)\n",
    "        fail += 1\n",
    "        continue\n",
    "\n",
    "    words = flatten_whisper_words(result)\n",
    "    if not words:\n",
    "        print(f\" id={num} â†’ no word-level timestamps from Whisper\")\n",
    "        fail += 1\n",
    "        continue\n",
    "\n",
    "    start_sec, end_sec = find_best_idiom_span(words, idiom_tokens, MIN_MATCH_RATIO)\n",
    "    if start_sec is None or end_sec is None:\n",
    "        print(f\" id={num} â†’ could not align idiom in ASR transcript (best match < {MIN_MATCH_RATIO})\")\n",
    "        fail += 1\n",
    "        continue\n",
    "\n",
    "    # small padding\n",
    "    start_pad = 0.1\n",
    "    end_pad   = 0.3\n",
    "    start_sec = max(0.0, start_sec - start_pad)\n",
    "    end_sec   = end_sec + end_pad\n",
    "\n",
    "    try:\n",
    "        cut_audio_segment(audio_path, start_sec, end_sec, out_path)\n",
    "        print(f\" saved idiom slice â†’ {out_path}\")\n",
    "        ok += 1\n",
    "    except Exception as e:\n",
    "        print(f\" id={num} â†’ error cutting audio:\", e)\n",
    "        fail += 1\n",
    "\n",
    "print(\"\\n=== DONE ===\")\n",
    "print(\" Slices created:\", ok)\n",
    "print(\" Skipped:\", skipped)\n",
    "print(\" Failed:\", fail)\n",
    "print(\"Output folder:\", os.path.abspath(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd pass only processes failed (missing) idioms, same logic\n",
    "\n",
    "extra_ok, extra_fail, extra_skipped = 0, 0, 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    num = ids[idx]\n",
    "    raw = row[COLUMN]\n",
    "\n",
    "    if pd.isna(raw) or str(raw).strip() == \"\":\n",
    "        extra_skipped += 1\n",
    "        continue\n",
    "\n",
    "    idiom_raw = str(raw).strip()\n",
    "    prefix = f\"{int(num):04d}\"\n",
    "    base_slug = slugify(idiom_raw.lower())[:60]\n",
    "    out_file  = f\"{prefix}_{base_slug}_idiom.mp3\"\n",
    "    out_path  = os.path.join(OUTPUT_DIR, out_file)\n",
    "\n",
    "    # if file already exists, skip\n",
    "    if os.path.exists(out_path):\n",
    "        extra_skipped += 1\n",
    "        continue\n",
    "\n",
    "    candidates = prefix_map.get(prefix, [])\n",
    "    if not candidates:\n",
    "        print(f\"[2nd pass] id={num} ({idiom_raw!r}) â†’ no long audio\")\n",
    "        extra_fail += 1\n",
    "        continue\n",
    "\n",
    "    audio_file = candidates[0]\n",
    "    audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
    "\n",
    "    print(f\"\\n2nd pass for id={num} | file={audio_file} | idiom={idiom_raw}\")\n",
    "\n",
    "    idiom_tokens = tokenize_idiom(idiom_raw)\n",
    "    if not idiom_tokens:\n",
    "        print(f\"[2nd pass] no tokens for id={num}\")\n",
    "        extra_skipped += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        result = model.transcribe(\n",
    "            audio_path,\n",
    "            language=LANG_CODE,\n",
    "            word_timestamps=True,\n",
    "            verbose=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[2nd pass] id={num} â†’ Whisper error:\", e)\n",
    "        extra_fail += 1\n",
    "        continue\n",
    "\n",
    "    words = flatten_whisper_words(result)\n",
    "    if not words:\n",
    "        print(f\"[2nd pass] id={num} â†’ no word timestamps\")\n",
    "        extra_fail += 1\n",
    "        continue\n",
    "\n",
    "    start_sec, end_sec = find_best_idiom_span(words, idiom_tokens, min_ratio=0.4)\n",
    "    if start_sec is None or end_sec is None:\n",
    "        print(f\"[2nd pass] id={num} â†’ still no good match\")\n",
    "        extra_fail += 1\n",
    "        continue\n",
    "\n",
    "    start_pad = 0.1\n",
    "    end_pad   = 0.3\n",
    "    start_sec = max(0.0, start_sec - start_pad)\n",
    "    end_sec   = end_sec + end_pad\n",
    "\n",
    "    try:\n",
    "        cut_audio_segment(audio_path, start_sec, end_sec, out_path)\n",
    "        print(f\"[2nd pass] saved idiom slice â†’ {out_path}\")\n",
    "        extra_ok += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[2nd pass] id={num} â†’ error cutting audio:\", e)\n",
    "        extra_fail += 1\n",
    "\n",
    "print(\"\\n=== 2nd pass done ===\")\n",
    "print(\"Extra slices created:\", extra_ok)\n",
    "print(\"Extra skipped:\", extra_skipped)\n",
    "print(\"Extra failed:\", extra_fail)\n",
    "print(\"Output folder:\", os.path.abspath(OUTPUT_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
